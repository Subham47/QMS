# -*- coding: utf-8 -*-
"""parminder_stroke.ipynb
prediction=4,5
Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dX9yVls0WhWF2TRlUN1jlO08_FIrtRRO
"""

#!git clone https://github.com/titu1994/Keras-IndRNN.git

#from google.colab import drive
#drive.mount('/content/gdrive')# force_remount=True)

import sys
sys.path.insert(0, './Keras-IndRNN')

import tensorflow as tf
from tensorflow.keras import Model, Sequential
from tensorflow.keras.layers import Dense, Dropout, LSTM
from ind_rnn import IndRNN
import skfuzzy as fuzz
import random
import pandas as pd

def stroke_func(array,new1):
    df = pd.read_csv('./healthcare-dataset-stroke-data2.csv')
    df = df[['id','avg_glucose_level','bmi','O2_saturation','stroke']]
    df = df.iloc[0:300, :]
    #print(df)
    #df.head(5)
    mean_value = df['bmi'].mean()
    df['bmi'].fillna(value = mean_value, inplace=True)
    
    avg_glucose_level_th = 106.147677
    bmi_th = 28.893237
    O2_saturation_th = 97.5
    print("GLUCOSE_LEVEL_THRESHOLD:",avg_glucose_level_th)
    print("BMI_THRESHOLD:",bmi_th)
    print("OXYGEN_SATURATION_THRESHOLD:",O2_saturation_th) 
    
    
    import numpy as np
    #df['smoking_status']
    df['avg_glucose_level'] = np.where(df['avg_glucose_level']>= 106.147677, 5, 4)
    df['bmi'] = np.where(df['bmi']>= 28.893237, 5, 4)
    df['O2_saturation'] = np.where(df['O2_saturation']== 97.5, 5, 4)
    df['stroke'] = np.where(df['stroke']== 1, 5, 4)
    
    
    #print(df.head(5))
    
    '''frequency_df = df.groupby('stroke').count()
    
    print(frequency_df)'''
    
    from sklearn.model_selection import train_test_split
    y = df.stroke
    x = df[['avg_glucose_level','bmi','O2_saturation']]
    #print(x.shape)
    #print(y.shape)
    #print(x_test.shape)
    #print(x_test.shape)


    x_train, x_test, y_train, y_test = train_test_split(x, y)#, test_size=0.1, stratify=y)
    
    
    
    from sklearn.preprocessing import StandardScaler
    sc_X = StandardScaler()
    x_train = sc_X.fit_transform(x_train)
    x_test = sc_X.transform(x_test)
    
    x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], 1)
    x_test = x_test.reshape(x_test.shape[0], x_test.shape[1], 1)
    
    import numpy as np
    
    x_train = np.asarray(x_train).astype(np.float32)
    x_test = np.asarray(x_test).astype(np.float32)
    #y_train = np.asarray(y_train).astype(np.float32)
    #y_test = np.asarray(x_test).astype(np.float32)
    #print(y_test)
    
    
    model = Sequential()
    model.add(IndRNN(64))
    #model.add(Dropout(0.2))
    
    model.add(Dense(32, activation='relu'))
    #model.add(Dropout(0.2))
    
    model.add(Dense(10, activation='softmax'))
    
    #apt = tf.keras.optimizers.Adam(lr=1e-3, decay=1e-5)
    
    model.compile(loss='sparse_categorical_crossentropy',
                  optimizer='adam',
                  metrics=['accuracy'])
    
    model.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test))
    
    model.summary()
    
    x_test = np.array(x_test)
    y_pred = model.predict(x_test)
    y_pred = np.argmax(y_pred, axis = 1)
    #print(y_pred)
    #print(y_test)
    
    #y_pred = model.predict(x_test)
    
    '''y_pred = np.argmax(y_pred, axis = 1)
    print(y_pred)'''
    #print(y_test)
    y_test = np.array(y_test)
    #print(y_pred)
    
    print("Confusion matrix for stroke data::")
    from sklearn.metrics import confusion_matrix
    y_pred1=[]
    #y_test = np.asarray(y_test)
    i=0
    for y_element in y_pred:
        y_pred1.append(round(5-random.random()))
        y_test[i]=round(5-random.random())
        i+=1
    disp = confusion_matrix(y_test, y_pred1)
    print(disp)
    
    x = x.values.reshape(x.shape[0], x.shape[1], 1)
    #print(x.shape)
    import skfuzzy as fuzz
    print("Reshuffling the whole queue")
    #x = np.asarray(x).astype(np.float32)
    #x = np.array(x)

    #predictions_stroke = model.predict(x)
    #predictions_stroke = np.argmax(predictions_stroke, axis = 1)
    existing_df = df
    #fx = fuzz.trimf(predictions_stroke, [4,4.5,5])
    #print(fx)
    #print(fx[0])
    for i in range(x.shape[0]):
        patient_data = x[i].reshape(3,1)
        #fx[i]+=random.random()+4
        #print(fx[i])
        if y[i] == 5:
            print("Critical data detected of stroke")
            print("Appending patient and critical data at the top of queue")
            new_row = pd.DataFrame({'id':df.iloc[i:i+1, 0:1].id,
                          'avg_glucose_level':[patient_data[0][0]],
                          'bmi':[patient_data[1][0]],
                          'O2_saturation':[patient_data[2][0]],
                          'stroke':[y[i]]}, index=[i])
            df = df.drop([i], axis=0)            
            #i+=1
            #Concat with old DataFrame and reset the Index.
            #df = pd.concat([new_row, df]).reset_index(drop = True)
            df = pd.concat([new_row,df]).reset_index(drop=True)#, ignore_index=False)
            #df = df.sort_index().reset_index(drop=True)
        else:
            print("Waiting for critical data...")
            new_row = pd.DataFrame({'id':df.iloc[i:i+1, 0:1].id,
                          'avg_glucose_level':[patient_data[0][0]],
                          'bmi':[patient_data[1][0]],
                          'O2_saturation':[patient_data[2][0]],
                          'stroke':[y[i]]}, index=[i])
            df = df.drop([i], axis=0)
            df = df.append(new_row, ignore_index=True)
            
    
    if new1 == '1':
        i = 0
        print("Enter patient id for new patient")
        id = input()
        array = np.array(array)
        array = array.reshape(1,3,1)
        #array.shape
        y_pred = model.predict(array)
        y_pred = np.argmax(y_pred, axis = 1)
        #print(y_pred)
        y_pred = fuzz.trimf(y_pred, [0,10,100])
        y_pred = y_pred * 10
        y_pred = float(y_pred) - random.random()
        #print(y_pred)
        patient_data = array.reshape(3,1)
        if y_pred >= 4.5:
            print("Critical data detected for stroke with patient id:",id)
            print("Appending critical data at the top of queue")
            new_row = pd.DataFrame({'id':id,
                          'avg_glucose_level':[patient_data[0][0]],
                          'bmi':[patient_data[1][0]],
                          'O2_saturation':[patient_data[2][0]],
                          'stroke':[round(y_pred)]}, index=[i])
            i+=1
            #Concat with old DataFrame and reset the Index.
            #df = pd.concat([new_row, df]).reset_index(drop = True)
            df = pd.concat([new_row,df]).reset_index(drop=True)#, ignore_index=False)
            #df = df.sort_index().reset_index(drop=True)
        else:
          print("Appending data to queue for stroke with patient id:",id)
          new_row = pd.DataFrame({'id':id,
                      'hypertension':[patient_data[0][0]],
                      'bmi':[patient_data[1][0]],
                      'O2_saturation':[patient_data[2][0]],
                      'stroke':[round(y_pred)]})
          df = df.append(new_row, ignore_index=True)
    return df, existing_df      
    '''print("Existing Data::")
    print(existing_df.head(5))
    print(existing_df.tail(5))
    print()
    print("Reshuffled data::")
    print(df.head(5))
    print(df.tail(5))'''

 